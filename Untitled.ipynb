{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc029bb",
      "metadata": {
        "id": "fcc029bb"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 설정\n",
        "a = '2004|2005|2006|2007|2008|2009|2010|2011|2012|2013|2014|2015|2016|2017|2018|2019|2020|2021|2022'\n",
        "learning = [0.001, 0.001, 0.01, 0.01]\n",
        "lamb1 = [0.00001, 0.001, 0.00001, 0.001]\n",
        "\n",
        "# 모델링을 위한 빈 리스트 초기화\n",
        "NN1_CRPs = {}\n",
        "num_models = 10\n",
        "\n",
        "# 상위 1%부터 15%까지 반복\n",
        "for p in range(1, 16):\n",
        "    d = 0\n",
        "    ya0, tk0, ym0, ya1 = [], [], [], []\n",
        "    yb0, tk1, ym1, yb1 = [], [], [], []\n",
        "\n",
        "    for i in range(11):\n",
        "        np.random.seed((i + 1) * 100)\n",
        "        X_test = XX[ym.str.contains(a[40 + 5 * i:44 + 5 * i])]\n",
        "        y_test = yy[ym.str.contains(a[40 + 5 * i:44 + 5 * i])]\n",
        "\n",
        "        otk = tk[ym.str.contains(a[40 + 5 * i:44 + 5 * i])]\n",
        "        oym = ym[ym.str.contains(a[40 + 5 * i:44 + 5 * i])]\n",
        "\n",
        "        r = [1] * 4\n",
        "        irr = []\n",
        "\n",
        "        for j in range(3):\n",
        "            X_train = XX[ym.str.contains(a[:24 + 5 * (j + i)])]\n",
        "            X_val = XX[ym.str.contains(a[25 + 5 * (j + i):29 + 5 * (j + i)])]\n",
        "            y_train = yy[ym.str.contains(a[:24 + 5 * (j + i)])]\n",
        "            y_val = yy[ym.str.contains(a[25 + 5 * (j + i):29 + 5 * (j + i)])]\n",
        "\n",
        "            ym_temp = X_val['yearmonth'].reset_index(drop=True)\n",
        "            key_yearmonth = dict.fromkeys(ym_temp)\n",
        "\n",
        "            y_val.reset_index(drop=True, inplace=True)\n",
        "\n",
        "            X_train = X_train.drop(['yearmonth', '종목코드'], axis=1)\n",
        "            X_val = X_val.drop(['yearmonth', '종목코드'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "            model1=Sequential() #레이어를 선형스택으로 쌓겠다.\n",
        "            model1.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model1.add(BatchNormalization()) # default: mementum=0.99 # 각 미니배치의 평균과 표준 편차를 정규화하여 학습을 안정화시키는 역할\n",
        "            model1.add(Dense(1,kernel_regularizer=regularizers.l1(0.00001)))\n",
        "            # relu ? | no activation or 'linear' #0.00001: 정규화의강도\n",
        "            # 0.0001: 모델의 가중치(W)에 대한 패널티를 부과하여 모델의 복잡도를 제어\n",
        "            model1.compile(loss='MSE',optimizer=adam_1,metrics=['MSE'])\n",
        "            model1.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred1 = pd.Series(model1.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred1[t]*p)/10)\n",
        "                sort = pred1[t].sort_values()\n",
        "                r1 = r1*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "            model2=Sequential()\n",
        "            model2.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model2.add(BatchNormalization())\n",
        "            model2.add(Dense(1, kernel_regularizer=regularizers.l1(0.001))) # relu ?\n",
        "            model2.compile(loss='MSE',optimizer=adam_1,metrics=['MSE'])\n",
        "            model2.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred2 = pd.Series(model2.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred2[t])*p/10)\n",
        "                sort = pred2[t].sort_values()\n",
        "                r2 = r2*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "            model3=Sequential()\n",
        "            model3.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model3.add(BatchNormalization())\n",
        "            model3.add(Dense(1, kernel_regularizer=regularizers.l1(0.00001))) # relu ?\n",
        "            model3.compile(loss='MSE',optimizer=adam_2,metrics=['MSE'])\n",
        "            model3.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred3 = pd.Series(model3.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred3[t])*p/10)\n",
        "                sort = pred3[t].sort_values()\n",
        "                r3 = r3*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "            model4=Sequential()\n",
        "            model4.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model4.add(BatchNormalization())\n",
        "            model4.add(Dense(1, kernel_regularizer=regularizers.l1(0.001))) # relu ?\n",
        "            model4.compile(loss='MSE',optimizer=adam_2,metrics=['MSE'])\n",
        "            model4.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred4 = pd.Series(model4.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred4[t])*p/10)\n",
        "                sort = pred4[t].sort_values()\n",
        "                r4 = r4*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "        irr1=r1*(-1)\n",
        "        irr2=r2*(-1)\n",
        "        irr3=r3*(-1)\n",
        "        irr4=r4*(-1)\n",
        "\n",
        "        irr = [irr1,irr2,irr3,irr4]\n",
        "        m = irr.index(min(irr))\n",
        "\n",
        "        # i를 사용하게 변경\n",
        "        ###################################################\n",
        "        Xt = XX[ym.str.contains(a[:24+5*i])]\n",
        "        Xv = XX[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        Xtv = XX[ym.str.contains(a[:39+5*i])]\n",
        "        yt = yy[ym.str.contains(a[:24+5*i])]\n",
        "        yv = yy[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        ytv = yy[ym.str.contains(a[:39+5*i])]\n",
        "\n",
        "        vtk = tk[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        vym = ym[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        ####################################################\n",
        "\n",
        "        np.random.seed(1000)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(32, input_shape=(40,), activation='relu', kernel_initializer='he_normal'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dense(1, kernel_regularizer=regularizers.l1(lamb1[m])))\n",
        "        model.compile(loss='mse', optimizer=adam_m, metrics=['mse'])\n",
        "        model.fit(Xt.drop(['yearmonth', '종목코드'], axis=1), yt, epochs=100, batch_size=10000, callbacks=[EarlyStopping()])\n",
        "\n",
        "        valid_pred = np.array(model.predict(Xv.drop(['yearmonth', '종목코드'], axis=1)))\n",
        "        val_y = valid_pred.reshape(-1,)\n",
        "\n",
        "        # 앙상블\n",
        "\n",
        "        # 모델설정\n",
        "        num_models = 10\n",
        "        model_outputs = []\n",
        "\n",
        "        for num in range(num_models):\n",
        "            # 모델별 다른 시드 설정\n",
        "            np.random.seed(1000 * (i + 1))\n",
        "\n",
        "            # 모델생성\n",
        "            model = Sequential()\n",
        "            model.add(Dense(32, input_shape=(40,), activation='relu', kernel_initializer='he_normal'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dense(1, kernel_regularizer=regularizers.l1(lamb1[m])))\n",
        "            model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "            # 학습\n",
        "            model.fit(Xtv.drop(['yearmonth', '종목코드'], axis=1), ytv, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            # 예측\n",
        "            yhat = model.predict(X_test.drop(['yearmonth', '종목코드'], axis=1))\n",
        "            model_outputs.append(yhat)\n",
        "\n",
        "        # 앙상블 평균\n",
        "        ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
        "        yhats = np.array(ensemble_output)\n",
        "        yy0 = yhats.reshape(-1,)\n",
        "        ya0 = ya0 + y_test.tolist()\n",
        "        ya1 = ya1 + yy0.tolist()\n",
        "        tk0 = tk0 + otk.tolist()\n",
        "        ym0 = ym0 + oym.tolist()\n",
        "\n",
        "        yb0 = yb0 + yv.tolist()\n",
        "        yb1 = yb1 + val_y.tolist()\n",
        "        tk1 = tk1 + vtk.tolist()\n",
        "        ym1 = ym1 + vym.tolist()\n",
        "        # 결과 저장\n",
        "        NN1_CRPs[f'NN1_CRP{p}'] = pd.DataFrame({'yearmonth': ym0, 'ticker': tk0, 'real': ya0, 'predict': ya1})\n",
        "\n",
        "# 모든 NN1_CRP 데이터프레임을 파일로 저장\n",
        "for p in range(1, 16):\n",
        "    NN1_CRPs[f'NN1_CRP{p}'].to_csv(f'NN1_CRP{p}.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63db0ef",
      "metadata": {
        "id": "d63db0ef"
      },
      "outputs": [],
      "source": [
        "# 모델링을 위한 빈 리스트 초기화\n",
        "NN1_CRPs = {}\n",
        "\n",
        "# 상위1%에서 상위15%까지 반복\n",
        "\n",
        "for p in range(1,16) :\n",
        "    a = '2004|2005|2006|2007|2008|2009|2010|2011|2012|2013|2014|2015|2016|2017|2018|2019|2020|2021|2022'\n",
        "    learning = [0.001,0.001,0.01,0.01]\n",
        "    lamb1 = [0.00001,0.001,0.00001,0.001]\n",
        "    shap_NN1 = []\n",
        "    d = 0\n",
        "    ya0 = []\n",
        "    tk0 = []\n",
        "    ym0 = []\n",
        "    ya1 = []\n",
        "\n",
        "    yb0 = []\n",
        "    tk1 = []\n",
        "    ym1 = []\n",
        "    yb1 = []\n",
        "\n",
        "    for i in range(11):\n",
        "        np.random.seed((i+1)*100)\n",
        "        X_test = XX[ym.str.contains(a[40+5*i:44+5*i])] # 2012 (1년)\n",
        "        y_test = yy[ym.str.contains(a[40+5*i:44+5*i])]\n",
        "\n",
        "        otk = tk[ym.str.contains(a[40+5*i:44+5*i])]\n",
        "        oym = ym[ym.str.contains(a[40+5*i:44+5*i])]\n",
        "\n",
        "        r1=1\n",
        "        r2=1\n",
        "        r3=1\n",
        "        r4=1\n",
        "\n",
        "        for j in range(3): # 3 fold이므로 3+i에서 3으로 수정\n",
        "            X_train = XX[ym.str.contains(a[:24+5*(j+i)])] # j에서 (i+j)로 변경\n",
        "            X_val = XX[ym.str.contains(a[25+5*(j+i):29+5*(j+i)])]\n",
        "            y_train = yy[ym.str.contains(a[:24+5*(j+i)])]\n",
        "            y_val = yy[ym.str.contains(a[25+5*(j+i):29+5*(j+i)])]\n",
        "\n",
        "            # for문에 필요한 key를 미리 만듦\n",
        "            ym_temp = X_val['yearmonth'].reset_index(drop=True) # t = ym_temp==k를 위해 reset index\n",
        "            key_yearmonth = dict.fromkeys(ym_temp)\n",
        "\n",
        "            # vy의 index를 reset\n",
        "            y_val.reset_index(drop=True, inplace=True) # r = r*(vy[sort[-d:].index].mean()+100)/100를 위해 reset index\n",
        "\n",
        "            # 년도, 티커 드랍\n",
        "            X_train = X_train.drop(['yearmonth', '종목코드'], axis=1)\n",
        "            X_val = X_val.drop(['yearmonth', '종목코드'], axis=1)\n",
        "\n",
        "            # fitting\n",
        "            model1=Sequential() #레이어를 선형스택으로 쌓겠다.\n",
        "            model1.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model1.add(BatchNormalization()) # default: mementum=0.99 # 각 미니배치의 평균과 표준 편차를 정규화하여 학습을 안정화시키는 역할\n",
        "            model1.add(Dense(1,kernel_regularizer=regularizers.l1(0.00001)))\n",
        "            # relu ? | no activation or 'linear' #0.00001: 정규화의강도\n",
        "            # 0.0001: 모델의 가중치(W)에 대한 패널티를 부과하여 모델의 복잡도를 제어\n",
        "            model1.compile(loss='MSE',optimizer=adam_1,metrics=['MSE'])\n",
        "            model1.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred1 = pd.Series(model1.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred1[t])*p/100)\n",
        "                sort = pred1[t].sort_values()\n",
        "                r1 = r1*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "            model2=Sequential()\n",
        "            model2.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model2.add(BatchNormalization())\n",
        "            model2.add(Dense(1, kernel_regularizer=regularizers.l1(0.001))) # relu ?\n",
        "            model2.compile(loss='MSE',optimizer=adam_1,metrics=['MSE'])\n",
        "            model2.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred2 = pd.Series(model2.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred2[t])*p/100)\n",
        "                sort = pred2[t].sort_values()\n",
        "                r2 = r2*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "            model3=Sequential()\n",
        "            model3.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model3.add(BatchNormalization())\n",
        "            model3.add(Dense(1, kernel_regularizer=regularizers.l1(0.00001))) # relu ?\n",
        "            model3.compile(loss='MSE',optimizer=adam_2,metrics=['MSE'])\n",
        "            model3.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred3 = pd.Series(model3.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred3[t])*p/100)\n",
        "                sort = pred3[t].sort_values()\n",
        "                r3 = r3*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "            model4=Sequential()\n",
        "            model4.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer='he_normal')) # relu 썼으니 initializer 설정\n",
        "            model4.add(BatchNormalization())\n",
        "            model4.add(Dense(1, kernel_regularizer=regularizers.l1(0.001))) # relu ?\n",
        "            model4.compile(loss='MSE',optimizer=adam_2,metrics=['MSE'])\n",
        "            model4.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            pred4 = pd.Series(model4.predict(X_val).flatten())\n",
        "            for k in list(key_yearmonth):\n",
        "                t = ym_temp == k # 해당 month\n",
        "                d = round(len(pred4[t])*p/100)\n",
        "                sort = pred4[t].sort_values()\n",
        "                r4 = r4*(y_val[sort[-d:].index].mean()+100)/100\n",
        "\n",
        "        irr1=r1*(-1)\n",
        "        irr2=r2*(-1)\n",
        "        irr3=r3*(-1)\n",
        "        irr4=r4*(-1)\n",
        "\n",
        "        irr = [irr1,irr2,irr3,irr4]\n",
        "        m = irr.index(min(irr))\n",
        "\n",
        "        adam_m = legacy_optimizer.Adam(learning_rate=learning[m], beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "                                          name='Adam')\n",
        "        # i를 사용하게 변경\n",
        "        ###################################################\n",
        "        Xt = XX[ym.str.contains(a[:24+5*i])]\n",
        "        Xv = XX[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        Xtv = XX[ym.str.contains(a[:39+5*i])]\n",
        "        yt = yy[ym.str.contains(a[:24+5*i])]\n",
        "        yv = yy[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        ytv = yy[ym.str.contains(a[:39+5*i])]\n",
        "\n",
        "        vtk = tk[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        vym = ym[ym.str.contains(a[25+5*i:39+5*i])]\n",
        "        ####################################################\n",
        "\n",
        "        np.random.seed(1000)\n",
        "        model=Sequential()\n",
        "        model.add(Dense(32,input_shape=(40,),activation='relu', kernel_initializer=initializer))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dense(1, kernel_regularizer=regularizers.l1(lamb1[m])))\n",
        "        model.compile(loss='mse',optimizer=adam_m,metrics=['mse'])\n",
        "        model.fit(Xt.drop(['yearmonth', '종목코드'], axis=1), yt, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "        valid_pred = np.array(model.predict(Xv.drop(['yearmonth', '종목코드'], axis=1)))\n",
        "        val_y = valid_pred.reshape(-1,)\n",
        "\n",
        "        # 모델설정\n",
        "        num_models = 10\n",
        "        model_outputs = []\n",
        "\n",
        "        for i in range(num_models):\n",
        "            # 모델별 다른 시드 설정\n",
        "            np.random.seed(1000 * (i + 1))\n",
        "\n",
        "            # 모델생성\n",
        "            model = Sequential()\n",
        "            model.add(Dense(32, input_shape=(40,), activation='relu', kernel_initializer='he_normal'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dense(1, kernel_regularizer=regularizers.l1(lamb1[m])))\n",
        "            model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "            # 학습\n",
        "            model.fit(Xtv.drop(['yearmonth', '종목코드'], axis=1), ytv, epochs=100, batch_size=10000, callbacks=[early_stopping])\n",
        "\n",
        "            # 예측\n",
        "            yhat = model.predict(X_test.drop(['yearmonth', '종목코드'], axis=1))\n",
        "            model_outputs.append(yhat)\n",
        "\n",
        "        # 앙상블 평균\n",
        "        ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
        "        yhats = np.array(ensemble_output)\n",
        "        yy0 = yhats.reshape(-1,)\n",
        "        ya0 = ya0 + y_test.tolist()\n",
        "        ya1 = ya1 + yy0.tolist()\n",
        "        tk0 = tk0 + otk.tolist()\n",
        "        ym0 = ym0 + oym.tolist()\n",
        "\n",
        "        yb0 = yb0 + yv.tolist()\n",
        "        yb1 = yb1 + val_y.tolist()\n",
        "        tk1 = tk1 + vtk.tolist()\n",
        "        ym1 = ym1 + vym.tolist()\n",
        "\n",
        "        #explainer= shap.KernelExplainer(modelm1.predict, shap.sample(Xt.drop(['yearmonth', '종목코드'], axis=1), 100, random_state=511))\n",
        "        #shap_values = explainer.shap_values(shap.sample(Xt.drop(['yearmonth', '종목코드'], axis=1), 100, random_state=511))\n",
        "        #shap_NN1.append(np.apply_along_axis(my_func, 1, abs(shap_values[0])))\n",
        "\n",
        "        #d = d + sum((np.array(y_test)-yy0)**2)\n",
        "        #print(m+1)\n",
        "\n",
        "\n",
        "    NN1_CRPs[f'NN1_CRP{p}'] = pd.DataFrame({'yearmonth': ym0, 'ticker': tk0, 'real': ya0, 'predict': ya1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99cadef4",
      "metadata": {
        "id": "99cadef4"
      },
      "outputs": [],
      "source": [
        "# 모든 NN1_CRP 데이터프레임을 파일로 저장\n",
        "for p in range(1, 16):\n",
        "    NN1_CRPs[f'NN1_CRP{p}'].to_csv(f'NN1_CRP{p}.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803f1daf",
      "metadata": {
        "id": "803f1daf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('NN1_CRP1.csv')\n",
        "\n",
        " # yearmonth 별로 해당 백분위수의 ticker 선택\n",
        "top_per = df.groupby('yearmonth').apply(lambda x: x.nlargest(int(len(x) * 1 / 100), 'predict'))\n",
        "\n",
        "# 'yearmonth' 열의 이름을 변경\n",
        "top_per = top_per.rename(columns={'yearmonth': 'yearmonth_grouped'})\n",
        "\n",
        "# 선택된 ticker들의 실제 수익률 계산(동일비율투자가정, 포폴의 월별수익률)\n",
        "average_real_return = top_per.groupby('yearmonth_grouped')['real'].mean()\n",
        "\n",
        "# 월평균수익률 계산\n",
        "mean_return = average_real_return.mean()\n",
        "\n",
        "# 월누적수익률 계산\n",
        "cum_return = (1+average_real_return/100).cumprod() - 1\n",
        "cum_return = cum_return.iloc[-1]\n",
        "\n",
        "\n",
        "# 최소수익률(최대손실률)\n",
        "#min_return = average_real_return.min()\n",
        "\n",
        "# 표준편차\n",
        "std_deviation = average_real_return.std()\n",
        "\n",
        "# Historical 95% VaR 계산\n",
        "var_95 = np.percentile(average_real_return, 5)\n",
        "\n",
        "#Maximum Drawdown\n",
        "cum_cum_return = (1+average_real_return/100).cumprod() - 1\n",
        "mdd = calculate_mdd(cum_cum_return)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}